<div class="essay">
<p>Trains no longer “choo-choo”, yet we still do. In our collective imagination, electro-locomotive doesn’t sound much different from its steam ancestor from a hundred years ago. A borrowed name for sound that represents the root cause of the machine lives in us, echoing its origin in the collective imagination. Somehow, it stuck to a Western passerby, who heard the first steam engine run, acclaimed this human will over tons of steel, and coined its complexity into the simplicity of a sound that it makes. Something that moved, burned, screamed, and insisted on presence. This “choo-choo” marks the beginning of an era when a semi-autonomous mechanism was heard by us, and we invited its speech into ours. In a very similar manner to how toddlers (who are also semi-autonomous before a certain age) unwrap their language from babble into an established speech, we are now, a century later, witnessing a physical establishment of our collective subconsciousness in the form of a ChatGPT. Another machine, imitating speech. To trace back its root access to language, I might even argue that “choo-choo” was not an onomatopoeic moment; it was a borrowing moment — but I wouldn’t. In any way, a machine spoke to us convincingly of what it does and what it is, to which we listened carefully and noted it down. Now we are worried whether the evolvement of the techno will convince us to do stupid things, as its speech apparatus goes from opportunistic gibberisherian noises of steam leaving the nozzle to academic essays written in a split of a second.</p>

<p>And under the hood, it always was and still is a wood-fired stove that heats water, meanwhile the supply chain behind it has grown. Yet it still hasn’t broken free from the chains of some fuel-heating-water device. We just put it on steroids by making a turbine revolve from tons of evaporating water heated via a controlled nuclear fission chain reaction. A spectacle of excess, overlooking how it arrived at the dead end of categorization. And now we are at this very promising (by Sam Altman, founder of OpenAI) moment — that by means of evolving language inside a machine, we can find access to new horizons of science, moving towards giving up excessive water-boiling technology.</p>

<p>On the pathway towards it, we decided to teach the machine how to draw. And graphic design, suddenly, is facing a very interesting time. An automation time. Let us consider a designer, chained by metaphysical anxiety with a brewing deep inside them sense of losing a job, while seeing a website design being assembled on a screen in one prompt, interrupted by a question from AI, that takes a brief pause from its labour: “What’s going to be the URL for this website?” And when the tremble is almost gone, in hands reaching towards the keyboard, there is already another machine waiting to break free, in a Shrek-like motion, slamming somebody's laboratory door where further experimentation with language is being held to solve problems. Problems, problems, problems — when are we going to have them all solved, so all these start-ups with two-syllable names will nihiliate themselves? According to, almost speculative, calculations… We can assume that a syllable in English consists of an onset, a vowel nucleus, and a coda. Based on phonotactic analysis of the English language, there are approximately ninety possible syllable onsets, which include single consonants, two-consonant clusters, three-consonant clusters, and the possibility of no onset at all. For the vowel nucleus, English has about sixteen distinct vowel sounds, including both monophthongs and diphthongs. As for codas, there are around twenty-one possibilities, including twenty distinct final consonant clusters and the option of having no coda. When combining these parts, we get approximately twenty-six thousand unique syllables that conform to English phonotactic rules. If we then consider all possible two-syllable combinations — where any legal syllable may be followed by any other — the number of potential two-syllable words is the square of the total number of syllables. Squaring twenty-six thousand results in approximately six hundred seventy-six million possible two-syllable word combinations. This figure represents the upper bound of phonotactically legal, pronounceable two-syllable forms in English, regardless of whether they correspond to real or meaningful words. Do we really have enough problems in the world for all those yet-to-be-established start-ups?</p>

<p>The number of stars we can see at once varies, it is not that easily identifiable. We first have to experience them. Location, altitude, eyesight, weather, and local light pollution will take part. In a city, we might see fewer than a few dozen stars. In a rural area with minimal light pollution, maybe a few thousand. Conditions in the polar regions of the globe are often more inviting to look at stars, as the night spans for a couple of months. And there must’ve been once a Yakut on this earth, marching through the crisp snow of Taiga, whose pace would gradually decrease, bringing him down on his back to look and listen to the stars as they “whisper” to him. And there must’ve been a poet next to him, with whom, yet unfrozen, he tried to share what he heard — and maybe this was the moment when “whisper of stars” made it into Yakutian to refer to the dead-freezing-cold. Someone who is charmed by Western romanticism would have to tear down a series of barriers before reaching, in their imagination, a state of understanding in which the first Yakuts found themselves when they heard what the stars had to say to them. So much is embedded in that ultimate understanding of the very cold weather in just two words — isn’t it fantastic? Who would’ve cared that water molecules coming out of our lungs crystallize almost instantly, making whispering sounds as they collide and fall down, once the temperature goes below fifty degrees Celsius — there is a very convincing poetry of the landscape unravelling here, when someone who hears it for the first time takes a pause to process all that embodiment in just two words: “whisper of stars.” I bet it instantly clicked with the first person who heard it from that poet, for the poet spoke from his experience of being beyond something untitled. It is empirical truth, not because stars can speak, but because language can expand in motions far more complex than juggling syllables, and — paradoxically — language appears to be more precise than science.</p>

<p>So we stand between two acts of naming: one in response to the machine's scream, the other to the sky's whisper. Both are irreducible. Both speak of how meaning is not made through logic, but pressure. The Yakut and a Western engineer both arrived at the naming thresholds — moments when experience overflowed its content. Let us now consider another designer drawing an interface for navigating a ballistic missile. Nuclear. Something stupidly powerful, able to bring an end for many, and for sure. The choice of a dot to represent the hit target region is asking to be chosen. It’s here, ecstatically spasming, reaching towards the designer out of their toolbox of borrowed meanings, for its spotlight moment. It is an excess of clarity, both for those sending and those receiving a missile. A square would be an absolutely aesthetic option meant for pleasing the back of generals’ heads with shaved hairlines. And the designer here, knowingly or not, appears in a similar situation as Yakut poets and Western engineers: between things that demand names and those that refuse them. This is where it all starts — with the desire to name, for it never begins with theory, nor with function, and absolutely not with billions of books absorbed inside AI’s blackbox. It starts with an attempt to grasp the entity itself, before it becomes trapped in grids of concepts. Perhaps design is not about making objects conveniently usable, but about creating modes of perception itself, for things to be named. That anticipation of excessiveness was in the moment when the first man came across the notion that called for its name. So much of muchness concentrated in one point that it had to spill out into language and ask for a name for itself. With language being both motivated as a train running down the tracks and arbitrary as speaking stars, we still have hope for freedom from serfdom to techno as long as we are able to sense The Untitled — and the machine is bamboozled by the paradoxical nature of the language that we taught it. And while the machine’s speech apparatus, even the one available to the public, is already far superior to what a human can produce, The Untitled is still out there existing non-exhausted, and this is where I take a wild bet — that we are long before an AI will have its true “choo-choo” moment. Echoes of meaning that resist formal classification are on our side, together with The Untitled reaching out for our experience preceding categorization, throwing wrenches in the cogs of progress. All I hope for is that when an archi-ultra-super-intelligent AI emerges, it won't be so annoyed by our language too much that it decides to eliminate us instead of double-syllable start-ups.</p>
</div>